{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSVbPdwn2TSXKiUZKa4IQQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdoulKidakou/M1SLED/blob/main/Introduction_aux_m%C3%A9thodes_de_traitement_de_texte.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FEATURE ENGINEERING\n",
        "\n",
        "# Main Objective:\n",
        "\n",
        "To explore and illustrate how text can be preprocessed and represented as vectors for effective use in predictive models. This notebook serves as a foundation for more advanced textual data analysis."
      ],
      "metadata": {
        "id": "p0WBWPAvv0Js"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importation des bibliothèques nécessaires\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "import nltk"
      ],
      "metadata": {
        "id": "-LdNOrmIx20s"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Télécharger les ressources nécessaires de NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG4KO_vex6b2",
        "outputId": "ab5850d3-e471-4e96-ba9a-598ad1801597"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemple de corpus (liste de documents)\n",
        "corpus = [\n",
        "    \"Sous le ciel bleu, les étoiles dansent,\",\n",
        "    \"La nature chante en douce cadence.\",\n",
        "    \"Les rêves s'élèvent, portés par le vent,\",\n",
        "    \"Un monde de paix, simple et charmant.\"\n",
        "]"
      ],
      "metadata": {
        "id": "Xd6kuW5uyCa7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this Notebook is to demonstrate various text processing techniques used in feature engineering to convert textual data into numerical representations that can be utilized by machine learning models. These techniques include:\n",
        "\n",
        "# 1.    Bag-of-Words (BoW): Transforming text into frequency vectors of words."
      ],
      "metadata": {
        "id": "TATOgwNMxYYZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-E4-froQlEog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe883a9d-3e37-4eaf-93de-f22533c18184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Bag-of-Words ===\n",
            "Feature Names: ['bleu' 'cadence' 'chante' 'charmant' 'ciel' 'dansent' 'de' 'douce' 'en'\n",
            " 'et' 'la' 'le' 'les' 'monde' 'nature' 'paix' 'par' 'portés' 'rêves'\n",
            " 'simple' 'sous' 'un' 'vent' 'élèvent' 'étoiles']\n",
            "Bag-of-Words Matrix:\n",
            " [[1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1]\n",
            " [0 1 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 1 1 0]\n",
            " [0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "# 1. Bag-of-Words\n",
        "print(\"\\n=== Bag-of-Words ===\")\n",
        "vectorizer_bow = CountVectorizer()\n",
        "X_bow = vectorizer_bow.fit_transform(corpus)\n",
        "print(\"Feature Names:\", vectorizer_bow.get_feature_names_out())\n",
        "print(\"Bag-of-Words Matrix:\\n\", X_bow.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.   n-Grams and Bag-of-n-Grams: Capturing sequences of consecutive words to enrich context.**\n",
        "\n"
      ],
      "metadata": {
        "id": "7oMsZhpiyPUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. N-gram (exemple avec bi-grammes)\n",
        "print(\"\\n=== N-gram (Bi-grams) ===\")\n",
        "vectorizer_ngram = CountVectorizer(ngram_range=(2, 2))\n",
        "X_ngram = vectorizer_ngram.fit_transform(corpus)\n",
        "print(\"Feature Names:\", vectorizer_ngram.get_feature_names_out())\n",
        "print(\"N-gram Matrix:\\n\", X_ngram.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1ZxxOnjyOA0",
        "outputId": "dd2caf4c-b7b0-4ac7-8399-21e793f49ff5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== N-gram (Bi-grams) ===\n",
            "Feature Names: ['bleu les' 'chante en' 'ciel bleu' 'de paix' 'douce cadence' 'en douce'\n",
            " 'et charmant' 'la nature' 'le ciel' 'le vent' 'les rêves' 'les étoiles'\n",
            " 'monde de' 'nature chante' 'paix simple' 'par le' 'portés par'\n",
            " 'rêves élèvent' 'simple et' 'sous le' 'un monde' 'élèvent portés'\n",
            " 'étoiles dansent']\n",
            "N-gram Matrix:\n",
            " [[1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1]\n",
            " [0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 1 0]\n",
            " [0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Frequency-Based and Presence-Based Representations: Comparing representations based on raw word frequencies and binary presence indicators.**\n",
        "\n"
      ],
      "metadata": {
        "id": "n093S_R4yiY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Frequency-based vs Presence-based\n",
        "print(\"\\n=== Frequency-based ===\")\n",
        "X_frequency = vectorizer_bow.fit_transform(corpus).toarray()\n",
        "print(\"Frequency Matrix:\\n\", X_frequency)\n",
        "\n",
        "print(\"\\n=== Presence-based ===\")\n",
        "X_presence = np.where(X_frequency > 0, 1, 0)\n",
        "print(\"Presence Matrix:\\n\", X_presence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0swmX7lhyhiB",
        "outputId": "db1c3ddb-ed46-48e6-ce3b-947df5be31b5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Frequency-based ===\n",
            "Frequency Matrix:\n",
            " [[1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1]\n",
            " [0 1 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 1 1 0]\n",
            " [0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0]]\n",
            "\n",
            "=== Presence-based ===\n",
            "Presence Matrix:\n",
            " [[1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1]\n",
            " [0 1 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 1 1 0]\n",
            " [0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Stemming: Reducing words to their root forms to simplify analysis.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mSDn1DSDyu3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Stemming\n",
        "print(\"\\n=== Stemming ===\")\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('french'))\n",
        "for i, doc in enumerate(corpus):\n",
        "    tokens = word_tokenize(doc.lower())\n",
        "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
        "    print(f\"Document {i+1} après stemming: {stemmed_tokens}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xE1wKj9yvc3",
        "outputId": "c709d4a9-fc18-4262-9fbc-402f6f40a644"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Stemming ===\n",
            "Document 1 après stemming: ['sou', 'ciel', 'bleu', 'étoil', 'dansent']\n",
            "Document 2 après stemming: ['natur', 'chant', 'douc', 'cadenc']\n",
            "Document 3 après stemming: ['rêve', 'porté', 'vent']\n",
            "Document 4 après stemming: ['mond', 'paix', 'simpl', 'charmant']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. TF-IDF (Term Frequency-Inverse Document Frequency): Weighting words based on their importance within a document relative to the entire corpus.**"
      ],
      "metadata": {
        "id": "bhvvi5Ehy6sQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. TF-IDF\n",
        "print(\"\\n=== TF-IDF ===\")\n",
        "vectorizer_tfidf = TfidfVectorizer()\n",
        "X_tfidf = vectorizer_tfidf.fit_transform(corpus)\n",
        "print(\"Feature Names:\", vectorizer_tfidf.get_feature_names_out())\n",
        "print(\"TF-IDF Matrix:\\n\", X_tfidf.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq5x6uNBy7IM",
        "outputId": "64b83a41-9107-40f7-8816-4b1917ad7277"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TF-IDF ===\n",
            "Feature Names: ['bleu' 'cadence' 'chante' 'charmant' 'ciel' 'dansent' 'de' 'douce' 'en'\n",
            " 'et' 'la' 'le' 'les' 'monde' 'nature' 'paix' 'par' 'portés' 'rêves'\n",
            " 'simple' 'sous' 'un' 'vent' 'élèvent' 'étoiles']\n",
            "TF-IDF Matrix:\n",
            " [[0.40021825 0.         0.         0.         0.40021825 0.40021825\n",
            "  0.         0.         0.         0.         0.         0.31553666\n",
            "  0.31553666 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.40021825 0.         0.         0.\n",
            "  0.40021825]\n",
            " [0.         0.40824829 0.40824829 0.         0.         0.\n",
            "  0.         0.40824829 0.40824829 0.         0.40824829 0.\n",
            "  0.         0.         0.40824829 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.31553666\n",
            "  0.31553666 0.         0.         0.         0.40021825 0.40021825\n",
            "  0.40021825 0.         0.         0.         0.40021825 0.40021825\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.37796447 0.         0.\n",
            "  0.37796447 0.         0.         0.37796447 0.         0.\n",
            "  0.         0.37796447 0.         0.37796447 0.         0.\n",
            "  0.         0.37796447 0.         0.37796447 0.         0.\n",
            "  0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fMtiRT7UzDH9"
      }
    }
  ]
}